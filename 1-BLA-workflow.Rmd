---
title: "Boundary lines for yield gap analysis, revisiting Fermont et al. (2009)"
author:
- Tomás Roquette Tenreiro$^a$ (PhD) and João Vasco Silva$^b$ (PhD)
- $^a$SISTAGRO - Systems Engineering in Agriculture
- $^b$CIMMYT-Zimbabwe & WUR-PPS
date: "`r format(Sys.time(), '%d-%B-%Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: yes
    fig_caption: yes
    css: style.css
    header-includes:
    - \usepackage{setspace}
    - \sinlgespacing
  pdf_document:
    toc: yes
    toc_depth: '2'
  word_document:
    toc: yes
    toc_depth: '2'
bibliography: references.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/ecology-letters.csl
---

```{r, echo=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

___

# **Introduction**

**PLEASE DEVELOP THIS TEXT**

Explain yield gap analysis and how boundary lines fit into that

Define the approach: 3 steps: 1) get BL points, 2) fit regressions and plot, 3) do the yield gap decomposition. For the latter please introduce the concepts of identified and unidentified yield gaps.

Provide background in the study of Fermont et al. Cassava in Kenya and Uganda, data points, key results from the paper.

___

# **Load required R packages**

First, we need to load the R packages needed to run this workflow.

```{r, warning=FALSE}
# package names
packages <- c("splines", "Metrics", "dplyr", "tidyr", "knitr", "reshape2", "ggplot2", "DT")

# install packages
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)){
  install.packages(packages[!installed_packages])}

# load packages
invisible(lapply(packages, library, character.only = TRUE))
```

___

# **Farmer field data**

**ADJUST AS NEEDED** The first step is to load the farmer field data to be used for yield gap analysis. The data contain (a) primary data on self-reported Ya, management practices, and biophysical conditions at field level obtained through a household survey, and (b) secondary data obtained from spatial products using the GPS coordinates of the individual households. The household survey is a panel of households over two growing seasons (2009 and 2013). Type and sources of secondary data include: climate zones from the Global Yield Gap Atlas [@vanWart2013], soil water properties from AfSIS-GYGA [@Leenaars2018], agro-ecological zones for Ethiopia [@MoA1998], and farming systems classification for Africa [@Tilahun2017].   

```{r}
# read .csv file with data
file <- 'https://raw.githubusercontent.com/jvasco323/EiA_BLA_workflow/main/fermont_etal_final.csv'
data <- read.csv(url(file))

# list variables of interest
str(data)
```

___

# **Data manipulation**

explain code below. Other things is to look at input variables, NA etc. Give advice.

```{r}
# remove outliers
data <- subset(data, yld_t0 < 30)
```

___

# **Descriptive statistics**

**ADJUST TEXT TO THE PRINTED TABLE BELOW** Descriptive statistics of the actual yield and (continuous) crop management variables used in the analysis for the 2 years of the survey are provided below. Actual yield of wheat across Ethiopia was on average 1.76 t/ha in 2009 and 1.77 t/ha in 2013. N and P application rates were on average 48 kg N/ha and 20 kg P/ha, respectively. Plot sizes were on average 0.45 ha in 2009 and 0.40 ha in 2013.

```{r, echo=FALSE, warning=FALSE}
vars3 <- c('year', 'RF_tot', 'clay', 'pH_soil', 'SOC', 'days_to_harvest', 'yld_t0')
# mean
numeric_cols_mean <- data[,vars3] %>%
  group_by(year) %>%
  summarise(across(
    .cols = where(is.numeric), 
    .fns = list(Mean = mean), na.rm = TRUE, 
    .names = "{col}"))
numeric_cols_mean <- round(numeric_cols_mean, 1)
numeric_cols_mean <- t(numeric_cols_mean)
colnames(numeric_cols_mean)[2] <- 'Mean 2005'
colnames(numeric_cols_mean)[1] <- 'Mean 2004'
numeric_cols_mean = numeric_cols_mean[-1,]
Variable <- rownames(numeric_cols_mean)
rownames(numeric_cols_mean) <- NULL
numeric_cols_mean <- cbind(Variable, numeric_cols_mean)
# sd
numeric_cols_sd <- data[,vars3] %>%
  group_by(year) %>%
  summarise(across(
    .cols = where(is.numeric), 
    .fns = list(SD = sd), na.rm = TRUE, 
    .names = "{col}"))
numeric_cols_sd <- round(numeric_cols_sd, 1)
numeric_cols_sd <- t(numeric_cols_sd)
colnames(numeric_cols_sd)[2] <- 'StDev 2005'
colnames(numeric_cols_sd)[1] <- 'StDev 2004'
numeric_cols_sd = numeric_cols_sd[-1,]
Variable <- rownames(numeric_cols_sd)
rownames(numeric_cols_sd) <- NULL
numeric_cols_sd <- cbind(Variable, numeric_cols_sd)
# merge
numeric_cols = merge(numeric_cols_mean, numeric_cols_sd, by='Variable')
numeric_cols$Variable[1] <- 'Soil clay content (%)'
numeric_cols$Variable[2] <- 'Days to harvest (d)'
numeric_cols$Variable[3] <- 'Soil pH'
numeric_cols$Variable[4] <- 'Growing season rainfall (mm)'
numeric_cols$Variable[5] <- 'Soil organic C (mg/kg)'
numeric_cols$Variable[6] <- 'Cassava yield (t/ha)'
# show
knitr::kable(numeric_cols)
```

___

# **Step 1: Field selection**

**Please describe the function below step by step** First paragraph, what it does generically. Second paragraph, two approaches implemented to identify ymax.  

```{r, warning=FALSE}
bl_points <- function(df, xvar, approach){
  
   # select the x variable of interest
   df <- df[,c("yld_t0", xvar)]
   
   # modify column names for generic use 
   colnames(df)[1] = "Y"
   colnames(df)[2] = "X"
   df <- subset(df, X>0, select=c(Y, X)) # why x > 0?
   
   # 'NULL' values are excluded to avoid data transformation problems and calculation failures 
   # correct NA values for both Y and X variables 
   df$Y[is.na(df$Y)] <- mean(df$Y, na.rm=T)
   df$X[is.na(df$X)] <- mean(df$X, na.rm=T)
   
   # split X variable in 10 quantiles (Fermont et al., 2009)
   x_0.1 <- subset(df, X <= quantile(X, 0.1))
   x_0.2 <- subset(df, X > quantile(X, 0.1) & X <= quantile(X, 0.2))
   x_0.3 <- subset(df, X > quantile(X, 0.2) & X <= quantile(X, 0.3))
   x_0.4 <- subset(df, X > quantile(X, 0.3) & X <= quantile(X, 0.4))
   x_0.5 <- subset(df, X > quantile(X, 0.4) & X <= quantile(X, 0.5))
   x_0.6 <- subset(df, X > quantile(X, 0.5) & X <= quantile(X, 0.6))
   x_0.7 <- subset(df, X > quantile(X, 0.6) & X <= quantile(X, 0.7))
   x_0.8 <- subset(df, X > quantile(X, 0.7) & X <= quantile(X, 0.8))
   x_0.9 <- subset(df, X > quantile(X, 0.8) & X <= quantile(X, 0.9))
   x_1.0 <- subset(df, X > quantile(X, 0.9) & X <= quantile(X, 1.0))

   # define boundary points for each quantile based on maximum value
   if(approach == 'maximum'){
    blp_0.0 <- subset(x_0.1, X == min(X)) #  briefly explain why needed
    blp_0.1 <- subset(x_0.1, Y == max(Y))
    blp_0.2 <- subset(x_0.2, Y == max(Y))
    blp_0.3 <- subset(x_0.3, Y == max(Y))
    blp_0.4 <- subset(x_0.4, Y == max(Y))
    blp_0.5 <- subset(x_0.5, Y == max(Y))
    blp_0.6 <- subset(x_0.6, Y == max(Y))
    blp_0.7 <- subset(x_0.7, Y == max(Y))
    blp_0.8 <- subset(x_0.8, Y == max(Y))
    blp_0.9 <- subset(x_0.9, Y == max(Y))
    blp_1.0 <- subset(x_1.0, Y == max(Y)) 

   # define boundary points for each quantile based on yields in given quantile
   } else if(approach == '95_quantile'){
    blp_0.0 <- subset(x_0.1, X == min(X)) 
    blp_0.1 <- subset(x_0.1, Y > quantile(Y, 0.95))
    blp_0.2 <- subset(x_0.2, Y > quantile(Y, 0.95))
    blp_0.3 <- subset(x_0.3, Y > quantile(Y, 0.95))
    blp_0.4 <- subset(x_0.4, Y > quantile(Y, 0.95))
    blp_0.5 <- subset(x_0.5, Y > quantile(Y, 0.95))
    blp_0.6 <- subset(x_0.6, Y > quantile(Y, 0.95))
    blp_0.7 <- subset(x_0.7, Y > quantile(Y, 0.95))
    blp_0.8 <- subset(x_0.8, Y > quantile(Y, 0.95))
    blp_0.9 <- subset(x_0.9, Y > quantile(Y, 0.95))
    blp_1.0 <- subset(x_1.0, Y > quantile(Y, 0.95))}

   # bind subsets
   blp_df <- rbind(blp_0.0, blp_0.1, blp_0.2, blp_0.3, blp_0.4, blp_0.5, 
                   blp_0.6, blp_0.7, blp_0.8, blp_0.9, blp_1.0)
   return(blp_df)}
```
___

# **Step 2: Boundary lines**

**Please describe the function below step by step** 

First we select the variables for which BL will be fitted. Please explain different ways on how to do this!!! and which criteria should be used for that+ what Fermont did.

```{r, warning=FALSE}
#variaveis <- c("pH_soil", "SOC", "totN_soil", "P_soil", "K_soil", "CBB_T0_9",
               #"CGM_T0_9", "RF_tot", "RF0_6M", "RF_.d", "clay", "days_to_harvest")
variaveis <- c("pH_soil", "totN_soil", "P_soil", "clay")
```

Second we create empty dataframes to store data (be specific which data etc)

```{r, warning=FALSE}
blp_new <- c()
data_new <- c()
rmse_df <- c()
```

Explain all steps in the loop below. 1st why we loop. And from there explain each of the six steps. [[I NEED TO FIND A WAY TO PLOT THE FIGURES TOGETHER, OUT OF THE LOOP]]

```{r, warning=FALSE}
for(i in unique(variaveis)){
  # print(i)
  
  # 1) selecionar data
  data_subset <- data[,c("year", "Trial", "Site", "Farm.no.", "yld_t0", i)]
  colnames(data_subset)[5] = "Y"
  colnames(data_subset)[6] = "X"
  data_subset$variable <- i
  
  # 2) estimar pontos de fronteira
  data.bla <- bl_points(data, i, approach="maximum")
  data.bla$variable <- i
  
  # 3) estimar regressao
  model <- glm(Y ~ ns(X, df = 2), data = data.bla)
  # print(model)
  
  # 4) predict y_max
  # boundary points only
  data.bla$y_pred <- predict(model, newdata = data.bla)
  # raw data
  data_subset$y_pred <- predict(model, newdata = data_subset)

  # 5) ERROR assessment
  rmse_value <- rmse(data.bla$Y, data.bla$y_pred)
  
  # for plotting
  # (para melhorar, meter plots fora do loop)
  plot_lims <- range(data_subset$X, na.rm=T)
  plot.grid <- seq(from=plot_lims[1], to=plot_lims[2])
  pred <- predict(model, newdata=list(X=plot.grid), se=T)
  spline.d <- as.data.frame(spline(data.bla$X, data.bla$y_pred))
  xmin <- min(data_subset$X)
  xmax <- max(data_subset$X)
  ymax <- max(data_subset$Y)
  g1 <- ggplot(data.bla, aes(x=X, y=y_pred)) + 
    geom_point(size=6, alpha=0.6, color="blue") +
    geom_point(data=data.bla, aes(x=X, y=Y), size=3, alpha=0.9, color="red") +
    geom_point(data=data_subset, aes(x=X, y=Y)) +
    coord_cartesian(xlim=c(xmin-2, xmax), ylim=c(0, ymax+5)) + 
    labs(title="BOUNDARY LINE ", subtitle="Spline method - Shatar & Mcbratney. (2004)", y="YIELD_tha",
         x="X", caption="[BL from 10 groups]") + 
    theme_bw() + 
    theme(text = element_text(size=15)) +
    geom_line(data = spline.d, aes(x = x, y = y), alpha=0.6, color="blue", size=2)
  print(g1)
  
  # 6) juntar tudo
  blp_new <- rbind(blp_new, data.bla)
  data_new <- rbind(data_new, data_subset)
  rmse_df <- rbind(rmse_df, cbind(i, rmse_value))}
```

___

# **Step 3: Yield gap analysis**

**Please adjust text** First reshape df to estimate y_pred_min and limiting factor

```{r, warning=FALSE}
# reshape df
data_ygd <- dcast(data_new, year + Trial + Site + Farm.no. + Y ~ variable, value.var='y_pred') 
data_ygd$y_pred_min = apply(data_ygd[6:9], 1, min) 
data_ygd$factor_limitante = names(data_ygd[6:9])[apply(data_ygd[6:9], 1, which.min)]
```

Second estimate IYG and UYG

```{r, warning=FALSE}
# decompose yg
data_ygd$IYG <- max(data_ygd$Y, na.rm=T) - data_ygd$y_pred_min
data_ygd$UYG <- data_ygd$y_pred_min - data_ygd$Y
```

Third make some plots and interpret them

```{r, warning=FALSE}
# plot 1
plot(data_ygd$y_pred_min, data_ygd$Y, xlim=c(0, 35), ylim=c(0, 35))
abline(a=0, b=1)
abline(a=0, b=0.5)

# plot 2
ggplot(data_ygd, aes(x=Y, y=data_ygd$y_pred_min, ymax = data_ygd$y_pred_min+IYG)) + 
  geom_point(size=2.5, alpha=0.6, color="blue") +
  geom_abline() +
  geom_pointrange(aes(ymin = y_pred_min, ymax = y_pred_min+IYG), data = data_ygd, width = 0.2, size=0.1, linetype='dashed', col = 'red')+
  geom_pointrange(aes(ymin = y_pred_min-UYG, ymax = y_pred_min), data = data_ygd, width = 0.2, size=0.1, linetype='dashed', col = 'green')+
  # Coords and axis limits
  geom_hline(yintercept=max(data_ygd$Y), size=1, linetype='dashed', col = 'red')+
  geom_hline(yintercept=0, linetype='dotted', col = 'red')+
  geom_vline(xintercept=0, linetype='dotted', col = 'red')+
  coord_cartesian(xlim=c(0, max(data_ygd$Y)), ylim=c(0, max(data_ygd$Y))) + 
  labs(title="Yield gap decomposition", subtitle="Following the method of Wairegi et al. (2010)", y="Predicted crop yield Y [t/ha]",
       x="Observed crop yield X [t/ha]", caption="") + theme_bw() + theme(text = element_text(size=15))

```

___

# **Recommendations**

**Please summarize here what we learnt with this** Good for datasets with clear responses to x, not for datasets close to yield potential. Subjective selection of BL points. Different models possible to fit regressions etc....

___

# **Acknowledgments**

We thank Ken Giller (WUR-PPS) and Piet van Asten (Olam International) for sharing the original data showcased in this workflow. The development of this notebook was possible thanks to the financial support from the OneCGIAR initiative on *Excellence in Agronomy*. For further support and questions on how to implement this workflow to other data sets, or further thoughts on how to improve the theoretical framework used, are almost welcome and should be addressed to **j.silva@cgiar.org**.   

___

# **References**

